import re
import streamlit as st
from openai import OpenAI, BadRequestError

st.set_page_config(page_title="GPT Webæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ”")
st.title("ğŸ” GPT Webæ¤œç´¢ãƒãƒ£ãƒƒãƒˆï¼ˆStreaming / Reasoning=Highï¼‰")

# --- ä¼šè©±ãƒ­ã‚°ã¨ç›´è¿‘ã®å…¨æ–‡ ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "_last_full_text" not in st.session_state:
    st.session_state._last_full_text = ""

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¨­å®šï¼†å‡ºå…¸ ---
with st.sidebar:
    st.header("è¨­å®š")
    model = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ï¼ˆResponses APIå¯¾å¿œï¼‰",
        [
            "gpt-4o",        # å®‰å®š: web_searchãƒ„ãƒ¼ãƒ«ï¼†ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã«å¯¾å¿œ
            "gpt-4o-mini",   # è»½é‡
            "gpt-5",         # åˆ©ç”¨æ¨©é™ãŒã‚ã‚‹å ´åˆã®ã¿ï¼ˆéå¯¾å¿œãªã‚‰ gpt-4o æ¨å¥¨ï¼‰
        ],
        index=0,
        help="*æ³¨æ„*: â€œ-search-previewâ€ç³»ã¯ Chat Completions å‘ã‘ã®è¨˜è¿°ãŒã‚ã‚Šã€Responses APIï¼‹web_searchã¨ç›¸æ€§ãŒæ‚ªã„ã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã™ã€‚"
    )
    enable_search = st.toggle("ã‚¦ã‚§ãƒ–æ¤œç´¢ã‚’è¨±å¯ï¼ˆtools=web_searchï¼‰", value=True)
    st.caption("ãƒ¢ãƒ‡ãƒ«ãŒå¯¾å¿œã—ã¦ã„ã‚Œã°ã€å¿…è¦ã«å¿œã˜ã¦Webæ¤œç´¢ãŒè‡ªå‹•ã§ä½¿ã‚ã‚Œã¾ã™ã€‚")

    st.markdown("---")
    st.header("å‡ºå…¸ï¼ˆè‡ªå‹•æŠ½å‡ºï¼‰")

    def render_sources(md_text: str):
        # [title](url) ã‚’å„ªå…ˆæŠ½å‡º
        links = re.findall(r"\[([^\]]+)\]\((https?://[^\s)]+)\)", md_text)
        urls = re.findall(r"(?<!\()(?P<url>https?://[^\s\)]+)", md_text)
        seen = set()
        for title, url in links:
            if url in seen: 
                continue
            st.markdown(f"- [{title}]({url})")
            seen.add(url)
        for url in urls:
            if url not in seen:
                st.markdown(f"- <{url}>")
                seen.add(url)

    render_sources(st.session_state._last_full_text)

# --- æ—¢å­˜ãƒ­ã‚°ã®æç”» ---
for role, content in st.session_state.messages:
    with st.chat_message("user" if role == "user" else "assistant"):
        st.markdown(content)

# --- OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ---
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# --- System æŒ‡ç¤ºï¼ˆå‡ºå…¸ã‚’å¿…ãšMarkdownãƒªãƒ³ã‚¯ã§ï¼‰ ---
SYSTEM_HINT = (
    "ã‚ãªãŸã¯æ—¥æœ¬èªã®ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å¿…è¦ãªã¨ãã«web_searchãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã„ã€"
    "æœ¬æ–‡ã®æœ€å¾Œã«å¿…ãšã€å‡ºå…¸ã€ã¨ã—ã¦ Markdown ãƒªãƒ³ã‚¯ï¼ˆ[ã‚¿ã‚¤ãƒˆãƒ«](URL)ï¼‰ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚"
    "æœ¬æ–‡ã¯ç°¡æ½”ã«è¦ç‚¹ã‹ã‚‰è¿°ã¹ã¦ãã ã•ã„ã€‚"
)

# --- å…¥åŠ›æ¬„ ---
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šã€2025å¹´ã®ç”ŸæˆAIãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¦ç´„ã—ã¦ã€ï¼‰"):
    st.session_state.messages.append(("user", prompt))
    with st.chat_message("user"):
        st.markdown(prompt)

    tools = [{"type": "web_search"}] if enable_search else []
    kwargs_reasoning = {"reasoning": {"effort": "high"}}  # æ¨è«–ãƒ¬ãƒ™ãƒ«ï¼å¼·ï¼ˆéå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã§ã¯ç„¡è¦–ãƒ»ã‚¨ãƒ©ãƒ¼æ™‚ã¯å¾Œè¿°ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

    # --- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§æœ¬æ–‡ã‚’æç”»ã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ ---
    def stream_once(_model, use_tools=True, use_reasoning=True):
        full = []
        extra = {}
        if use_reasoning:
            extra.update(kwargs_reasoning)

        with client.responses.stream(
            model=_model,
            input=[
                {"role": "system", "content": SYSTEM_HINT},
                {"role": "user", "content": prompt},
            ],
            tools=(tools if use_tools else []),
            **extra,
        ) as stream:
            for event in stream:
                if event.type == "response.output_text.delta":
                    chunk = event.delta
                    full.append(chunk)
                    yield chunk
                elif event.type == "response.completed":
                    break
                elif event.type == "response.error":
                    yield f"\n\n**[ã‚¨ãƒ©ãƒ¼]** {getattr(event, 'error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}\n"
        st.session_state._last_full_text = "".join(full)

    # --- è€éšœå®³åŒ–ï¼šBadRequest ã®ã¨ãã«æ®µéšçš„ã«ç·©ã‚ã‚‹ ---
    def robust_stream():
        try:
            # 1) æŒ‡å®šãƒ¢ãƒ‡ãƒ« + web_search + reasoning=high
            yield from stream_once(model, use_tools=True, use_reasoning=True)
            return
        except BadRequestError as e:
            st.toast("BadRequest: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª¿æ•´ã—ã¦å†è©¦è¡Œã—ã¾ã™ã€‚", icon="âš ï¸")
            # 2) reasoning ãªã—ã§å†è©¦è¡Œ
            try:
                yield from stream_once(model, use_tools=True, use_reasoning=False)
                return
            except BadRequestError:
                # 3) ãƒ„ãƒ¼ãƒ«ç„¡ã—ï¼ˆç´”ç²‹å›ç­”ï¼‰ã§å†è©¦è¡Œ
                try:
                    st.toast("web_searchãŒéå¯¾å¿œã®å¯èƒ½æ€§ â†’ ãƒ„ãƒ¼ãƒ«ç„¡ã—ã§å†è©¦è¡Œ", icon="â„¹ï¸")
                    yield from stream_once(model, use_tools=False, use_reasoning=False)
                    return
                except BadRequestError:
                    # 4) æœ€çµ‚æ‰‹æ®µ: ãƒ¢ãƒ‡ãƒ«ã‚’ gpt-4o ã«åˆ‡æ›¿ï¼ˆå¤šãã®ç’°å¢ƒã§å®‰å®šï¼‰
                    st.warning("é¸æŠãƒ¢ãƒ‡ãƒ«ãŒ Responses+web_search éå¯¾å¿œã®å¯èƒ½æ€§ã€‚`gpt-4o` ã§å†è©¦è¡Œã—ã¾ã™ã€‚")
                    yield from stream_once("gpt-4o", use_tools=True, use_reasoning=False)
                    return

    with st.chat_message("assistant"):
        st.write_stream(robust_stream())

    # å±¥æ­´ã«æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
    st.session_state.messages.append(("assistant", st.session_state._last_full_text))

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å‡ºå…¸ã‚’æ›´æ–°
    with st.sidebar:
        st.markdown("---")
        st.header("å‡ºå…¸ï¼ˆè‡ªå‹•æŠ½å‡ºï¼‰")
        links = re.findall(r"\[([^\]]+)\]\((https?://[^\s)]+)\)", st.session_state._last_full_text)
        urls = re.findall(r"(?<!\()(?P<url>https?://[^\s\)]+)", st.session_state._last_full_text)
        seen = set()
        for title, url in links:
            if url in seen:
                continue
            st.markdown(f"- [{title}]({url})")
            seen.add(url)
        for url in urls:
            if url not in seen:
                st.markdown(f"- <{url}>")
                seen.add(url)
